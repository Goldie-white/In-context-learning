#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯è§†åŒ–æµ‹è¯•ç»“æœ
é€’å½’æ‰«ææŒ‡å®šç›®å½•ï¼ˆé»˜è®¤ test_results/ï¼‰ï¼Œä¸ºæ¯ä¸ªè®­ç»ƒé…ç½®ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

ä½¿ç”¨æ–¹æ³•:
    python visualize.py                    # æ‰«æé»˜è®¤çš„ test_results/ ç›®å½•
    python visualize.py --input_dir /path/to/results  # æ‰«ææŒ‡å®šç›®å½•
"""

import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import re
import argparse
import sys

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (12, 8)


def extract_prob_from_dirname(dirname):
    """ä»ç›®å½•åæå–æ¦‚ç‡é…ç½®
    
    Args:
        dirname: ç›®å½•åï¼Œå¦‚ 'prob_0.25_0.25_0.25_0.25'
    
    Returns:
        tuple: (p0, p1, p2, p3) or None
    """
    match = re.match(r'prob_([\d.]+)_([\d.]+)_([\d.]+)_([\d.]+)', dirname)
    if match:
        return tuple(float(x) for x in match.groups())
    return None


def get_task_label(task_name):
    """è·å–ä»»åŠ¡æ ‡ç­¾"""
    task_labels = {
        'T1': 'Task 1: y=w^TÂ·x',
        'T2': 'Task 2: y=w^TÂ·sort(x)',
        'T3': 'Task 3: y=(d/âˆš2)Â·w^TÂ·softmax(x)',
        'T4': 'Task 4: y=||x-w||Â²'
    }
    return task_labels.get(task_name, task_name)


def get_training_label(probs):
    """æ ¹æ®è®­ç»ƒæ¦‚ç‡ç”Ÿæˆæ ‡ç­¾"""
    p0, p1, p2, p3 = probs
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºçº¯ä»»åŠ¡
    if p0 > 0.99:
        return 'Trained on Pure T1'
    elif p1 > 0.99:
        return 'Trained on Pure T2'
    elif p2 > 0.99:
        return 'Trained on Pure T3'
    elif p3 > 0.99:
        return 'Trained on Pure T4'
    else:
        # æ··åˆä»»åŠ¡
        return f'Trained on Mix (T1:{p0:.2f}, T2:{p1:.2f}, T3:{p2:.2f}, T4:{p3:.2f})'


def load_test_results(test_dir):
    """åŠ è½½æµ‹è¯•ç»“æœ
    
    Args:
        test_dir: æµ‹è¯•ç»“æœç›®å½•ï¼Œå¦‚ 'test_results/xdim_5/Y_pred/prob_1.0_0.0_0.0_0.0'
    
    Returns:
        dict: {task_name: data_dict}
    
    Note:
        å®é™…æ–‡ä»¶æ˜¯ y_analysis.pkl æˆ– w_analysis.pklï¼Œéœ€è¦ä»æ•°æ®ä¸­æˆ–æ–‡ä»¶åæ¨æ–­æµ‹è¯•ä»»åŠ¡
    """
    results = {}
    test_path = Path(test_dir)
    
    if not test_path.exists():
        return results
    
    # å°è¯•åŠ è½½ y_analysis.pkl æˆ– w_analysis.pklï¼ˆåŒ…æ‹¬ MC Dropout ç‰ˆæœ¬ï¼‰
    pkl_files = (list(test_path.glob('y_analysis.pkl')) + 
                 list(test_path.glob('w_analysis.pkl')) +
                 list(test_path.glob('y_mc_analysis.pkl')) +
                 list(test_path.glob('w_mc_analysis.pkl')))
    
    if not pkl_files:
        # å…¼å®¹æ—§æ ¼å¼ï¼šæ‰«ææ‰€æœ‰ test_on_*.pkl æ–‡ä»¶
        pkl_files = list(test_path.glob('test_on_*.pkl'))
    
    for pkl_file in pkl_files:
        try:
            with open(pkl_file, 'rb') as f:
                data = pickle.load(f)
                
                # ä»æ–‡ä»¶åæˆ–æ•°æ®ä¸­æ¨æ–­ä»»åŠ¡åç§°
                if 'test_on_' in pkl_file.stem:
                    # æ—§æ ¼å¼ï¼štest_on_T1.pkl
                    task_name = pkl_file.stem.replace('test_on_', '')
                else:
                    # æ–°æ ¼å¼ï¼šä»ç›®å½•åæˆ–æ•°æ®ä¸­æ¨æ–­æµ‹è¯•ä»»åŠ¡
                    # ç›®å½•åæ ¼å¼ï¼šprob_0.0_0.0_0.0_1.0 è¡¨ç¤ºæµ‹è¯•æ—¶ä½¿ç”¨çš„ä»»åŠ¡æ¦‚ç‡
                    dirname = test_path.name
                    prob_match = re.match(r'prob_([\d.]+)_([\d.]+)_([\d.]+)_([\d.]+)', dirname)
                    if prob_match:
                        p0, p1, p2, p3 = tuple(float(x) for x in prob_match.groups())
                        # æ ¹æ®æ¦‚ç‡ç¡®å®šä»»åŠ¡ï¼ˆå‡è®¾åªæœ‰ä¸€ä¸ªéé›¶æ¦‚ç‡ï¼‰
                        if p0 > 0.99:
                            task_name = 'T1'
                        elif p1 > 0.99:
                            task_name = 'T2'
                        elif p2 > 0.99:
                            task_name = 'T3'
                        elif p3 > 0.99:
                            task_name = 'T4'
                        else:
                            # æ··åˆä»»åŠ¡ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªéé›¶æ¦‚ç‡
                            if p0 > 0:
                                task_name = 'T1'
                            elif p1 > 0:
                                task_name = 'T2'
                            elif p2 > 0:
                                task_name = 'T3'
                            else:
                                task_name = 'T4'
                    else:
                        # æ— æ³•æ¨æ–­ï¼Œä½¿ç”¨é»˜è®¤åç§°
                        task_name = 'T1'
                
                results[task_name] = data
        except Exception as e:
            print(f"Warning: Failed to load {pkl_file}: {e}")
    
    return results


def visualize_y_pred(test_dir, output_dir):
    """å¯è§†åŒ– Y é¢„æµ‹å™¨çš„æµ‹è¯•ç»“æœ
    
    Args:
        test_dir: Yé¢„æµ‹å™¨æµ‹è¯•ç»“æœç›®å½•
        output_dir: è¾“å‡ºå›¾ç‰‡ç›®å½•
    """
    results = load_test_results(test_dir)
    
    if not results:
        print(f"No results found in {test_dir}")
        return
    
    # æå–è®­ç»ƒé…ç½®
    dirname = Path(test_dir).name
    train_probs = extract_prob_from_dirname(dirname)
    if train_probs is None:
        print(f"Cannot parse training probs from {dirname}")
        return
    
    train_label = get_training_label(train_probs)
    
    # ä»æ•°æ®ä¸­æ¨æ–­åºåˆ—é•¿åº¦ä¿¡æ¯
    # æµ‹è¯•åºåˆ—é•¿åº¦ï¼šä»æ•°æ®æ•°ç»„é•¿åº¦æ¨æ–­ï¼ˆå¦‚ avg_y_loss çš„é•¿åº¦ï¼‰
    first_data = list(results.values())[0] if results else {}
    test_num_exemplars = None
    if first_data:
        # ä» avg_y_loss çš„é•¿åº¦æ¨æ–­æµ‹è¯•åºåˆ—é•¿åº¦
        if 'avg_y_loss' in first_data:
            test_num_exemplars = len(first_data['avg_y_loss'])
        elif 'y_mean_per_pos' in first_data:
            test_num_exemplars = len(first_data['y_mean_per_pos'])
    
    # è®­ç»ƒåºåˆ—é•¿åº¦ï¼šå°è¯•ä»ä¿å­˜çš„æ•°æ®ä¸­è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ä»è·¯å¾„æ¨æ–­
    train_num_exemplars = first_data.get('train_num_exemplars', None)
    if train_num_exemplars is None:
        # å°è¯•ä» exp_folder è·¯å¾„æ¨æ–­ï¼ˆå¦‚æœè·¯å¾„åŒ…å«åºåˆ—é•¿åº¦ä¿¡æ¯ï¼‰
        exp_folder = first_data.get('exp_folder', '')
        if exp_folder and 'num_exemplars' in str(exp_folder):
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è·¯å¾„è§£æé€»è¾‘
            pass
    
    # æ„å»ºåºåˆ—é•¿åº¦ä¿¡æ¯å­—ç¬¦ä¸²
    seq_info = ""
    if test_num_exemplars is not None:
        if train_num_exemplars is not None:
            if train_num_exemplars == test_num_exemplars:
                seq_info = f" (Train & Test: {train_num_exemplars} exemplars)"
            else:
                seq_info = f" (Train: {train_num_exemplars}, Test: {test_num_exemplars} exemplars)"
        else:
            seq_info = f" (Test: {test_num_exemplars} exemplars)"
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(1, 1, figsize=(12, 6))
    
    # é¢œè‰²æ˜ å°„
    colors = {'T1': '#1f77b4', 'T2': '#ff7f0e', 'T3': '#2ca02c', 'T4': '#d62728'}
    markers = {'T1': 'o', 'T2': 's', 'T3': '^', 'T4': 'D'}
    
    # ç”»æ¯ä¸ªæµ‹è¯•ä»»åŠ¡çš„æ›²çº¿
    for task_name in sorted(results.keys()):
        data = results[task_name]
        avg_y_loss = data['avg_y_loss']
        positions = np.arange(1, len(avg_y_loss) + 1)
        
        ax.plot(positions, avg_y_loss,
                label=get_task_label(task_name),
                color=colors.get(task_name, 'gray'),
                marker=markers.get(task_name, 'o'),
                markersize=4,
                linewidth=2,
                alpha=0.8)
    
    ax.set_xlabel('Position', fontsize=12)
    ax.set_ylabel('Y Prediction Loss (MSE)', fontsize=12)
    ax.set_title(f'Y-Predictor: Loss vs Position\n{train_label}{seq_info}', fontsize=14, fontweight='bold')
    ax.legend(fontsize=10, loc='best')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(left=0)
    
    # ä¿å­˜å›¾ç‰‡
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, f'{dirname}_y_pred_loss.png')
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… Y-Pred visualization saved: {output_file}")


def visualize_w_pred(test_dir, output_dir, other_w_test_dir=None):
    """å¯è§†åŒ– W é¢„æµ‹å™¨çš„æµ‹è¯•ç»“æœï¼ˆå¯åŒæ—¶å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬ï¼‰
    
    Args:
        test_dir: Wé¢„æµ‹å™¨æµ‹è¯•ç»“æœç›®å½•ï¼ˆW_pred æˆ– W_pred_loss_Wï¼‰
        output_dir: è¾“å‡ºå›¾ç‰‡ç›®å½•
        other_w_test_dir: å¦ä¸€ä¸ªWé¢„æµ‹å™¨ç‰ˆæœ¬çš„ç»“æœç›®å½•ï¼ˆç”¨äºå¯¹æ¯”ï¼‰ï¼Œå¯ä¸ºNone
    """
    results = load_test_results(test_dir)
    
    if not results:
        print(f"No results found in {test_dir}")
        return
    
    # å°è¯•åŠ è½½å¦ä¸€ä¸ªWé¢„æµ‹å™¨ç‰ˆæœ¬çš„ç»“æœï¼ˆå¦‚æœæä¾›ï¼‰
    other_results = {}
    if other_w_test_dir:
        if Path(other_w_test_dir).exists():
            other_results = load_test_results(other_w_test_dir)
            if other_results:
                print(f"    âœ… Loaded {len(other_results)} tasks from {other_w_test_dir}")
            else:
                print(f"    âš ï¸  No results loaded from {other_w_test_dir}")
        else:
            print(f"    âš ï¸  Path does not exist: {other_w_test_dir}")
    
    # ç¡®å®šå½“å‰ç‰ˆæœ¬åç§°
    test_path = Path(test_dir)
    is_loss_w = 'W_pred_loss_W' in str(test_dir)
    current_version = 'W_pred_loss_W' if is_loss_w else 'W_pred'
    other_version = 'W_pred' if is_loss_w else 'W_pred_loss_W'
    
    # æå–è®­ç»ƒé…ç½®
    dirname = Path(test_dir).name
    train_probs = extract_prob_from_dirname(dirname)
    if train_probs is None:
        print(f"Cannot parse training probs from {dirname}")
        return
    
    train_label = get_training_label(train_probs)
    
    # ä»æ•°æ®ä¸­æ¨æ–­åºåˆ—é•¿åº¦ä¿¡æ¯
    first_data = list(results.values())[0] if results else {}
    test_num_exemplars = None
    if first_data:
        # ä»æ•°æ®æ•°ç»„é•¿åº¦æ¨æ–­æµ‹è¯•åºåˆ—é•¿åº¦
        if 'avg_y_loss' in first_data:
            test_num_exemplars = len(first_data['avg_y_loss'])
        elif 'w_mse_per_pos' in first_data:
            test_num_exemplars = len(first_data['w_mse_per_pos'])
    
    train_num_exemplars = first_data.get('train_num_exemplars', None)
    
    # æ„å»ºåºåˆ—é•¿åº¦ä¿¡æ¯å­—ç¬¦ä¸²
    seq_info = ""
    if test_num_exemplars is not None:
        if train_num_exemplars is not None:
            if train_num_exemplars == test_num_exemplars:
                seq_info = f" (Train & Test: {train_num_exemplars} exemplars)"
            else:
                seq_info = f" (Train: {train_num_exemplars}, Test: {test_num_exemplars} exemplars)"
        else:
            seq_info = f" (Test: {test_num_exemplars} exemplars)"
    
    # å°è¯•åŠ è½½å¯¹åº”çš„Y-predictorç»“æœï¼ˆç”¨äºç¬¬4ä¸ªå­å›¾ï¼‰
    # ä» test_dir ä¸­æ‰¾åˆ°å¯¹åº”çš„ Y_pred ç›®å½•
    # å¦‚æœ test_dir æ˜¯ xdim_*/W_pred/prob_...ï¼Œåˆ™æ‰¾ xdim_*/Y_pred/prob_...
    if 'W_pred' in str(test_dir):
        y_test_dir = str(test_path.parent.parent / 'Y_pred' / test_path.name)
    else:
        y_test_dir = test_dir.replace('/W_pred/', '/Y_pred/').replace('/W_pred_loss_W/', '/Y_pred/')
    y_results = load_test_results(y_test_dir) if Path(y_test_dir).exists() else {}
    
    # åˆ›å»º2x2å››å®«æ ¼å¸ƒå±€
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # é¢œè‰²æ˜ å°„
    colors = {'T1': '#1f77b4', 'T2': '#ff7f0e', 'T3': '#2ca02c', 'T4': '#d62728'}
    # å¦ä¸€ä¸ªç‰ˆæœ¬ä½¿ç”¨ä¸åŒçš„é¢œè‰²ï¼ˆç”¨äºåŒºåˆ†ï¼Œç¡®ä¿æ˜æ˜¾å¯è§ï¼‰
    colors_other = {'T1': '#9467bd', 'T2': '#ffbb78', 'T3': '#98df8a', 'T4': '#ff9896'}
    markers = {'T1': 'o', 'T2': 's', 'T3': '^', 'T4': 'D'}
    
    # å­å›¾1 (å·¦ä¸Š): Y Loss
    ax1 = axes[0, 0]
    # è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬çš„æ‰€æœ‰ä»»åŠ¡ï¼‰
    all_tasks = set(results.keys())
    if other_results:
        all_tasks.update(other_results.keys())
    
    for task_name in sorted(all_tasks):
        # ç»˜åˆ¶å½“å‰ç‰ˆæœ¬çš„æ•°æ®
        if task_name in results:
            data = results[task_name]
            avg_y_loss = data.get('avg_y_loss')
            if avg_y_loss is not None:
                positions = np.arange(1, len(avg_y_loss) + 1)
                ax1.plot(positions, avg_y_loss,
                         label=f'{get_task_label(task_name)} ({current_version})',
                         color=colors.get(task_name, 'gray'),
                         marker=markers.get(task_name, 'o'),
                         markersize=4,
                         linewidth=2.5,
                         alpha=0.9,
                         zorder=3)
        
        # ç»˜åˆ¶å¦ä¸€ä¸ªç‰ˆæœ¬çš„æ•°æ®
        if task_name in other_results:
            other_data = other_results[task_name]
            other_avg_y_loss = other_data.get('avg_y_loss')
            if other_avg_y_loss is not None:
                other_positions = np.arange(1, len(other_avg_y_loss) + 1)
                ax1.plot(other_positions, other_avg_y_loss,
                         label=f'{get_task_label(task_name)} ({other_version})',
                         color=colors_other.get(task_name, '#666666'),
                         marker='^',
                         markersize=5,
                         linewidth=2.5,
                         linestyle='--',
                         alpha=0.9,
                         zorder=4)
        
        # ç»˜åˆ¶ Y predictor çš„ loss æ›²çº¿
        if task_name in y_results:
            y_data = y_results[task_name]
            y_avg_y_loss = y_data.get('avg_y_loss')
            if y_avg_y_loss is not None:
                y_positions = np.arange(1, len(y_avg_y_loss) + 1)
                ax1.plot(y_positions, y_avg_y_loss,
                         label=f'{get_task_label(task_name)} (Y-Predictor)',
                         color=colors.get(task_name, 'gray'),
                         marker='*',
                         markersize=6,
                         linewidth=2.5,
                         linestyle=':',
                         alpha=0.9,
                         zorder=5)
    
    ax1.set_xlabel('Position', fontsize=11)
    ax1.set_ylabel('Y Loss', fontsize=11)
    ax1.set_title('(a) Y Prediction Loss', fontsize=12, fontweight='bold')
    ax1.legend(fontsize=9, loc='best')
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(left=0)
    
    # å­å›¾2 (å³ä¸Š): W MSE
    ax2 = axes[0, 1]
    # è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬çš„æ‰€æœ‰ä»»åŠ¡ï¼‰
    all_tasks = set(results.keys())
    if other_results:
        all_tasks.update(other_results.keys())
    
    for task_name in sorted(all_tasks):
        # ç»˜åˆ¶å½“å‰ç‰ˆæœ¬çš„æ•°æ®
        if task_name in results:
            data = results[task_name]
            w_mse = data.get('w_mse_per_pos')
            if w_mse is not None:
                positions = np.arange(1, len(w_mse) + 1)
                ax2.plot(positions, w_mse,
                         label=f'{get_task_label(task_name)} ({current_version})',
                         color=colors.get(task_name, 'gray'),
                         marker=markers.get(task_name, 'o'),
                         markersize=4,
                         linewidth=2.5,
                         alpha=0.9,
                         zorder=3)
        
        # ç»˜åˆ¶å¦ä¸€ä¸ªç‰ˆæœ¬çš„æ•°æ®
        if task_name in other_results:
            other_data = other_results[task_name]
            other_w_mse = other_data.get('w_mse_per_pos')
            if other_w_mse is not None:
                other_positions = np.arange(1, len(other_w_mse) + 1)
                ax2.plot(other_positions, other_w_mse,
                         label=f'{get_task_label(task_name)} ({other_version})',
                         color=colors_other.get(task_name, '#666666'),
                         marker='^',
                         markersize=5,
                         linewidth=2.5,
                         linestyle='--',
                         alpha=0.9,
                         zorder=4)
    
    ax2.set_xlabel('Position', fontsize=11)
    ax2.set_ylabel('W MSE (||w_pred - w_true||Â²)', fontsize=11)
    ax2.set_title('(b) W Prediction MSE', fontsize=12, fontweight='bold')
    ax2.legend(fontsize=9, loc='best')
    ax2.grid(True, alpha=0.3)
    ax2.set_xlim(left=0)
    
    # å­å›¾3 (å·¦ä¸‹): Cosine Similarity
    ax3 = axes[1, 0]
    # è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬çš„æ‰€æœ‰ä»»åŠ¡ï¼‰
    all_tasks = set(results.keys())
    if other_results:
        all_tasks.update(other_results.keys())
    
    for task_name in sorted(all_tasks):
        # ç»˜åˆ¶å½“å‰ç‰ˆæœ¬çš„æ•°æ®
        if task_name in results:
            data = results[task_name]
            cosine_sim = data.get('cosine_sim_mean')
            if cosine_sim is not None:
                positions = np.arange(1, len(cosine_sim) + 1)
                ax3.plot(positions, cosine_sim,
                         label=f'{get_task_label(task_name)} ({current_version})',
                         color=colors.get(task_name, 'gray'),
                         marker=markers.get(task_name, 'o'),
                         markersize=4,
                         linewidth=2.5,
                         alpha=0.9,
                         zorder=3)
        
        # ç»˜åˆ¶å¦ä¸€ä¸ªç‰ˆæœ¬çš„æ•°æ®
        if task_name in other_results:
            other_data = other_results[task_name]
            other_cosine_sim = other_data.get('cosine_sim_mean')
            if other_cosine_sim is not None:
                other_positions = np.arange(1, len(other_cosine_sim) + 1)
                ax3.plot(other_positions, other_cosine_sim,
                         label=f'{get_task_label(task_name)} ({other_version})',
                         color=colors_other.get(task_name, '#666666'),
                         marker='^',
                         markersize=5,
                         linewidth=2.5,
                         linestyle='--',
                         alpha=0.9,
                         zorder=4)
    
    ax3.set_xlabel('Position', fontsize=11)
    ax3.set_ylabel('Cosine Similarity', fontsize=11)
    ax3.set_title('(c) W Cosine Similarity (w_pred Â· w_true)', fontsize=12, fontweight='bold')
    ax3.legend(fontsize=9, loc='best')
    ax3.grid(True, alpha=0.3)
    ax3.set_xlim(left=0)
    ax3.set_ylim([-0.1, 1.1])
    
    # å­å›¾4 (å³ä¸‹): W-Predictor èŒƒæ•°æ›²çº¿å¯¹æ¯”
    ax4 = axes[1, 1]
    # è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬çš„æ‰€æœ‰ä»»åŠ¡ï¼‰
    all_tasks = set(results.keys())
    if other_results:
        all_tasks.update(other_results.keys())
    
    for task_name in sorted(all_tasks):
        # å…ˆç»˜åˆ¶w_trueçš„èŒƒæ•°ï¼ˆä½œä¸ºå‚è€ƒçº¿ï¼Œæ‰€æœ‰ä½ç½®ç›¸åŒï¼‰
        if task_name in results:
            data = results[task_name]
            w_true = data.get('w_true')  # shape: (n_samples, x_dim)
            w_preds = data.get('w_preds')  # shape: (n_samples, num_exemplars, x_dim)
            
            if w_true is not None and w_preds is not None:
                # è®¡ç®—w_trueçš„å¹³å‡èŒƒæ•°ï¼ˆå¯¹æ‰€æœ‰æ ·æœ¬æ±‚å¹³å‡ï¼‰
                w_true_norms = np.linalg.norm(w_true, axis=1)  # (n_samples,)
                w_true_norm_mean = np.mean(w_true_norms)
                
                # è·å–ä½ç½®æ•°é‡
                num_positions = w_preds.shape[1]
                positions = np.arange(1, num_positions + 1)
                
                # ç»˜åˆ¶w_trueèŒƒæ•°ï¼ˆæ°´å¹³çº¿ï¼‰
                ax4.axhline(y=w_true_norm_mean,
                           label=f'{get_task_label(task_name)} (Ground Truth)',
                           color='green',
                           linestyle=':',
                           linewidth=2.5,
                           alpha=0.8,
                           zorder=1)
        
        # ç»˜åˆ¶å½“å‰ç‰ˆæœ¬çš„w_predèŒƒæ•°
        if task_name in results:
            data = results[task_name]
            w_preds = data.get('w_preds')  # shape: (n_samples, num_exemplars, x_dim)
            if w_preds is not None:
                # è®¡ç®—æ¯ä¸ªä½ç½®çš„å¹³å‡L2èŒƒæ•°
                # w_preds: (n_samples, num_exemplars, x_dim)
                # norms: (n_samples, num_exemplars)
                norms = np.linalg.norm(w_preds, axis=2)
                # å¯¹æ‰€æœ‰æ ·æœ¬æ±‚å¹³å‡: (num_exemplars,)
                w_norm_mean = np.mean(norms, axis=0)
                positions = np.arange(1, len(w_norm_mean) + 1)
                
                ax4.plot(positions, w_norm_mean,
                         label=f'{get_task_label(task_name)} ({current_version})',
                         color=colors.get(task_name, 'gray'),
                         marker=markers.get(task_name, 'o'),
                         markersize=4,
                         linewidth=2.5,
                         alpha=0.9,
                         zorder=3)
        
        # ç»˜åˆ¶å¦ä¸€ä¸ªç‰ˆæœ¬çš„w_predèŒƒæ•°
        if task_name in other_results:
            other_data = other_results[task_name]
            other_w_preds = other_data.get('w_preds')
            if other_w_preds is not None:
                # è®¡ç®—æ¯ä¸ªä½ç½®çš„å¹³å‡L2èŒƒæ•°
                other_norms = np.linalg.norm(other_w_preds, axis=2)
                other_w_norm_mean = np.mean(other_norms, axis=0)
                other_positions = np.arange(1, len(other_w_norm_mean) + 1)
                
                ax4.plot(other_positions, other_w_norm_mean,
                         label=f'{get_task_label(task_name)} ({other_version})',
                         color=colors_other.get(task_name, '#666666'),
                         marker='^',
                         markersize=5,
                         linewidth=2.5,
                         linestyle='--',
                         alpha=0.9,
                         zorder=4)
    
    ax4.set_xlabel('Position', fontsize=11)
    ax4.set_ylabel('||w|| (L2 norm, mean)', fontsize=11)
    ax4.set_title('(d) W-Predictor Norm Comparison', fontsize=12, fontweight='bold')
    ax4.legend(fontsize=9, loc='best')
    ax4.grid(True, alpha=0.3)
    ax4.set_xlim(left=0)
    
    # æ€»æ ‡é¢˜
    title = f'W-Predictor: Analysis ({current_version}'
    if other_results:
        title += f' vs {other_version}'
    title += f')\n{train_label}{seq_info}'
    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.995)
    
    # ä¿å­˜å›¾ç‰‡
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, f'{dirname}_w_pred_analysis.png')
    plt.tight_layout(rect=[0, 0, 1, 0.99])
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… W-Pred visualization saved: {output_file}")


def compare_y_vs_w_predictor(y_test_dir, w_test_dir, w_loss_w_test_dir, output_dir):
    """å¯¹æ¯”Yé¢„æµ‹å™¨å’ŒWé¢„æµ‹å™¨ï¼ˆä¸¤ä¸ªç‰ˆæœ¬ï¼‰åœ¨åŒä¸€æµ‹è¯•ä»»åŠ¡ä¸Šçš„è¡¨ç°
    
    Args:
        y_test_dir: Yé¢„æµ‹å™¨æµ‹è¯•ç»“æœç›®å½•
        w_test_dir: Wé¢„æµ‹å™¨æµ‹è¯•ç»“æœç›®å½•ï¼ˆW_predï¼‰
        w_loss_w_test_dir: Wé¢„æµ‹å™¨Loss_Wæµ‹è¯•ç»“æœç›®å½•ï¼ˆW_pred_loss_Wï¼‰ï¼Œå¯ä¸ºNone
        output_dir: è¾“å‡ºå›¾ç‰‡ç›®å½•
    """
    # åŠ è½½ä¸‰ä¸ªé¢„æµ‹å™¨çš„ç»“æœ
    y_results = load_test_results(y_test_dir)
    w_results = load_test_results(w_test_dir)
    w_loss_w_results = load_test_results(w_loss_w_test_dir) if w_loss_w_test_dir and Path(w_loss_w_test_dir).exists() else {}
    
    if not y_results:
        print(f"  âš ï¸  Missing Y-Predictor results")
        return
    
    if not w_results and not w_loss_w_results:
        print(f"  âš ï¸  Missing W-Predictor results")
        return
    
    # æå–è®­ç»ƒé…ç½®
    dirname = Path(y_test_dir).name
    train_probs = extract_prob_from_dirname(dirname)
    if train_probs is None:
        return
    
    train_label = get_training_label(train_probs)
    
    # ä»æ•°æ®ä¸­æ¨æ–­åºåˆ—é•¿åº¦ä¿¡æ¯
    first_y_data = list(y_results.values())[0] if y_results else {}
    test_num_exemplars = None
    if first_y_data:
        if 'avg_y_loss' in first_y_data:
            test_num_exemplars = len(first_y_data['avg_y_loss'])
        elif 'y_mean_per_pos' in first_y_data:
            test_num_exemplars = len(first_y_data['y_mean_per_pos'])
    
    train_num_exemplars = first_y_data.get('train_num_exemplars', None)
    
    # æ„å»ºåºåˆ—é•¿åº¦ä¿¡æ¯å­—ç¬¦ä¸²
    seq_info = ""
    if test_num_exemplars is not None:
        if train_num_exemplars is not None:
            if train_num_exemplars == test_num_exemplars:
                seq_info = f" | Train & Test: {train_num_exemplars} exemplars"
            else:
                seq_info = f" | Train: {train_num_exemplars}, Test: {test_num_exemplars} exemplars"
        else:
            seq_info = f" | Test: {test_num_exemplars} exemplars"
    
    # æ‰¾å‡ºå…±åŒçš„æµ‹è¯•ä»»åŠ¡
    common_tasks = set(y_results.keys())
    if w_results:
        common_tasks = common_tasks & set(w_results.keys())
    if w_loss_w_results:
        common_tasks = common_tasks & set(w_loss_w_results.keys())
    
    if not common_tasks:
        print(f"  âš ï¸  No common test tasks")
        return
    
    # ä¸ºæ¯ä¸ªæµ‹è¯•ä»»åŠ¡åˆ›å»ºå¯¹æ¯”å›¾
    for task_name in sorted(common_tasks):
        y_data = y_results[task_name]
        w_data = w_results.get(task_name, {}) if w_results else {}
        w_loss_w_data = w_loss_w_results.get(task_name, {}) if w_loss_w_results else {}
        
        # åˆ›å»ºå›¾è¡¨ - ä¸»å›¾æ˜¾ç¤ºyå€¼ï¼Œå­å›¾æ˜¾ç¤ºè¯¯å·®
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), gridspec_kw={'height_ratios': [2, 1]})
        
        # æå–æ•°æ®
        y_true_mean = y_data.get('y_true_mean_per_pos', None)  # çœŸå®yå€¼
        y_pred_mean = y_data.get('y_mean_per_pos', None)  # Yé¢„æµ‹å™¨é¢„æµ‹çš„y
        w_y_pred_mean = w_data.get('y_pred_mean_per_pos', None) if w_data else None  # Wé¢„æµ‹å™¨é¢„æµ‹çš„y
        w_loss_w_y_pred_mean = w_loss_w_data.get('y_pred_mean_per_pos', None) if w_loss_w_data else None  # Wé¢„æµ‹å™¨Loss_Wé¢„æµ‹çš„y
        
        # è‡³å°‘éœ€è¦Yé¢„æµ‹å™¨çš„æ•°æ®
        if y_true_mean is None or y_pred_mean is None:
            print(f"    âš ï¸  Missing Y-Predictor data for {task_name}, skipping comparison")
            plt.close(fig)
            continue
        
        y_true_mean = y_true_mean.flatten()
        y_pred_mean = y_pred_mean.flatten()
        positions = np.arange(1, len(y_true_mean) + 1)
        
        # è®¡ç®—è¯¯å·®ï¼ˆåŸå§‹å€¼ï¼Œä¸ç”¨ç»å¯¹å€¼ï¼‰
        y_pred_error = y_pred_mean - y_true_mean
        
        # å¤„ç†Wé¢„æµ‹å™¨çš„æ•°æ®
        w_pred_error = None
        if w_y_pred_mean is not None:
            w_y_pred_mean = w_y_pred_mean.flatten()
            w_pred_error = w_y_pred_mean - y_true_mean
        
        w_loss_w_pred_error = None
        if w_loss_w_y_pred_mean is not None:
            w_loss_w_y_pred_mean = w_loss_w_y_pred_mean.flatten()
            w_loss_w_pred_error = w_loss_w_y_pred_mean - y_true_mean
        
        # === ä¸ŠåŠéƒ¨åˆ†ï¼šYå€¼æ›²çº¿ ===
        # 1. çœŸå®yå€¼
        ax1.plot(positions, y_true_mean,
                label='Ground Truth',
                color='green',
                marker='x',
                markersize=6,
                linewidth=3,
                linestyle='-',
                alpha=0.8,
                zorder=1)
        
        # 2. Yé¢„æµ‹å™¨é¢„æµ‹å€¼
        ax1.plot(positions, y_pred_mean,
                label='Y-Predictor',
                color='#1f77b4',
                marker='o',
                markersize=5,
                linewidth=2.5,
                linestyle='-',
                alpha=0.9,
                zorder=4)
        
        # 3. Wé¢„æµ‹å™¨é¢„æµ‹å€¼ï¼ˆW_predï¼‰
        if w_y_pred_mean is not None:
            ax1.plot(positions, w_y_pred_mean,
                    label='W-Predictor (W_pred)',
                    color='#ff7f0e',
                    marker='s',
                    markersize=5,
                    linewidth=2.5,
                    linestyle='--',
                    alpha=0.9,
                    zorder=3)
        
        # 4. Wé¢„æµ‹å™¨Loss_Wé¢„æµ‹å€¼ï¼ˆW_pred_loss_Wï¼‰
        if w_loss_w_y_pred_mean is not None:
            ax1.plot(positions, w_loss_w_y_pred_mean,
                    label='W-Predictor Loss_W (W_pred_loss_W)',
                    color='#d62728',
                    marker='^',
                    markersize=5,
                    linewidth=2.5,
                    linestyle='-.',
                    alpha=0.9,
                    zorder=2)
        
        ax1.set_xlabel('Position', fontsize=12)
        ax1.set_ylabel('Y Value (Mean across samples)', fontsize=12)
        ax1.set_title(f'Y-Predictor vs W-Predictors: Predictions and Errors\n{train_label} | Test on {get_task_label(task_name)}{seq_info}',
                     fontsize=14, fontweight='bold')
        ax1.legend(fontsize=11, loc='best', framealpha=0.9)
        ax1.grid(True, alpha=0.3)
        ax1.set_xlim(left=0)
        
        # æ·»åŠ æœ€ç»ˆä½ç½®çš„ç»Ÿè®¡ä¿¡æ¯
        y_true_final = y_true_mean[-1]
        y_pred_final = y_pred_mean[-1]
        y_pred_error_final = y_pred_error[-1]
        
        textstr_lines = [f'Final Position (#{len(positions)}):',
                        f'Ground Truth: {y_true_final:.4f}',
                        f'Y-Predictor: {y_pred_final:.4f}  (error: {y_pred_error_final:.4f})']
        
        if w_y_pred_mean is not None:
            w_pred_final = w_y_pred_mean[-1]
            w_pred_error_final = w_pred_error[-1]
            textstr_lines.append(f'W-Pred: {w_pred_final:.4f}  (error: {w_pred_error_final:.4f})')
        
        if w_loss_w_y_pred_mean is not None:
            w_loss_w_pred_final = w_loss_w_y_pred_mean[-1]
            w_loss_w_pred_error_final = w_loss_w_pred_error[-1]
            textstr_lines.append(f'W-Pred Loss_W: {w_loss_w_pred_final:.4f}  (error: {w_loss_w_pred_error_final:.4f})')
        
        textstr = '\n'.join(textstr_lines)
        props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
        ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=10,
                verticalalignment='top', horizontalalignment='left', bbox=props)
        
        # === ä¸‹åŠéƒ¨åˆ†ï¼šè¯¯å·®æ›²çº¿ ===
        ax2.plot(positions, y_pred_error,
                label='Y-Predictor Error',
                color='#1f77b4',
                marker='o',
                markersize=4,
                linewidth=2.5,
                linestyle='-',
                alpha=0.9)
        
        if w_pred_error is not None:
            ax2.plot(positions, w_pred_error,
                    label='W-Predictor Error (W_pred)',
                    color='#ff7f0e',
                    marker='s',
                    markersize=4,
                    linewidth=2.5,
                    linestyle='--',
                    alpha=0.9)
        
        if w_loss_w_pred_error is not None:
            ax2.plot(positions, w_loss_w_pred_error,
                    label='W-Predictor Loss_W Error',
                    color='#d62728',
                    marker='^',
                    markersize=4,
                    linewidth=2.5,
                    linestyle='-.',
                    alpha=0.9)
        
        # æ·»åŠ é›¶çº¿
        ax2.axhline(y=0, color='green', linestyle=':', linewidth=2, alpha=0.5, label='Zero Error')
        
        ax2.set_xlabel('Position', fontsize=12)
        ax2.set_ylabel('Error (y_pred - y_true)', fontsize=12)
        ax2.legend(fontsize=11, loc='best', framealpha=0.9)
        ax2.grid(True, alpha=0.3)
        ax2.set_xlim(left=0)
        # ç§»é™¤ bottom=0 é™åˆ¶ï¼Œå…è®¸æ˜¾ç¤ºè´Ÿå€¼
        
        # è¯¯å·®ç»Ÿè®¡ä¿¡æ¯å·²ç§»é™¤ï¼ˆé¿å…é®æŒ¡å›¾è¡¨ï¼‰
        
        # ä¿å­˜å›¾ç‰‡
        os.makedirs(output_dir, exist_ok=True)
        output_file = os.path.join(output_dir, f'{dirname}_compare_{task_name}.png')
        plt.tight_layout()
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"    âœ… Comparison saved: {output_file}")


def process_experiment_dir(exp_dir, output_base_name=None, base_dir=None):
    """å¤„ç†ä¸€ä¸ªå®éªŒç›®å½•ï¼Œç”Ÿæˆå¯è§†åŒ–
    
    Args:
        exp_dir: å®éªŒç›®å½•è·¯å¾„ï¼ˆPathå¯¹è±¡ï¼‰ï¼Œåº”åŒ…å« Y_pred, W_pred, W_pred_loss_W å­ç›®å½•
        output_base_name: è¾“å‡ºç›®å½•çš„åŸºç¡€åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨exp_dirçš„ç›¸å¯¹è·¯å¾„
        base_dir: åŸºç¡€ç›®å½•ï¼ˆPathå¯¹è±¡ï¼‰ï¼Œç”¨äºè®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨exp_dirçš„çˆ¶ç›®å½•
    """
    if output_base_name is None:
        # ç”Ÿæˆè¾“å‡ºç›®å½•åï¼šå°†è·¯å¾„ä¸­çš„ / æ›¿æ¢ä¸º _
        if base_dir is not None:
            try:
                rel_path = exp_dir.relative_to(base_dir)
                output_base_name = str(rel_path).replace('/', '_')
            except ValueError:
                # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç›®å½•å
                output_base_name = exp_dir.name
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šbase_dirï¼Œå°è¯•ä»exp_diræ¨æ–­
            # å¦‚æœexp_diråŒ…å«test_resultsï¼Œå»æ‰å®ƒ
            exp_str = str(exp_dir)
            if 'test_results' in exp_str:
                parts = exp_str.split('test_results')
                if len(parts) > 1:
                    rel_path = parts[1].lstrip('/')
                    output_base_name = rel_path.replace('/', '_') if rel_path else exp_dir.name
                else:
                    output_base_name = exp_dir.name
            else:
                output_base_name = exp_dir.name
    
    print(f"\nğŸ“ Processing directory: {exp_dir}")
    
    # å¯è§†åŒ– Y é¢„æµ‹å™¨ç»“æœ
    y_pred_dir = exp_dir / 'Y_pred'
    if y_pred_dir.exists():
        print("\n  ğŸ“Š Processing Y-Predictor results...")
        for prob_dir in sorted(y_pred_dir.iterdir()):
            if prob_dir.is_dir() and prob_dir.name.startswith('prob_'):
                print(f"    Processing: {prob_dir.name}")
                output_dir = f'visualization_results/{output_base_name}/Y_pred'
                visualize_y_pred(str(prob_dir), output_dir)
    
    # å¯è§†åŒ– W é¢„æµ‹å™¨ç»“æœï¼ˆåŒ…æ‹¬ W_pred å’Œ W_pred_loss_Wï¼ŒåŒæ—¶å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬ï¼‰
    w_pred_dir = exp_dir / 'W_pred'
    w_pred_loss_w_dir = exp_dir / 'W_pred_loss_W'
    
    # å¦‚æœä¸¤ä¸ªç‰ˆæœ¬éƒ½å­˜åœ¨ï¼Œåˆå¹¶ç”Ÿæˆä¸€ä»½å›¾ï¼›å¦‚æœåªæœ‰ä¸€ä¸ªï¼Œå•ç‹¬ç”Ÿæˆ
    if w_pred_dir.exists() and w_pred_loss_w_dir.exists():
        # ä¸¤ä¸ªç‰ˆæœ¬éƒ½å­˜åœ¨ï¼Œåˆå¹¶ç”Ÿæˆä¸€ä»½å›¾
        print(f"\n  ğŸ“Š Processing W-Predictor results (both versions)...")
        # è·å–æ‰€æœ‰å…±åŒçš„ prob ç›®å½•
        w_pred_probs = {d.name for d in w_pred_dir.iterdir() if d.is_dir() and d.name.startswith('prob_')}
        w_loss_w_probs = {d.name for d in w_pred_loss_w_dir.iterdir() if d.is_dir() and d.name.startswith('prob_')}
        common_probs = sorted(w_pred_probs & w_loss_w_probs)
        
        for prob_dir_name in common_probs:
            print(f"    Processing: {prob_dir_name}")
            w_pred_prob_dir = w_pred_dir / prob_dir_name
            w_loss_w_prob_dir = w_pred_loss_w_dir / prob_dir_name
            output_dir = f'visualization_results/{output_base_name}/W_pred'
            # ç”Ÿæˆåˆå¹¶å›¾ï¼ˆä»¥ W_pred ä¸ºä¸»ï¼Œå¯¹æ¯” W_pred_loss_Wï¼‰
            visualize_w_pred(str(w_pred_prob_dir), output_dir, str(w_loss_w_prob_dir))
    else:
        # åªæœ‰ä¸€ä¸ªç‰ˆæœ¬å­˜åœ¨ï¼Œå•ç‹¬ç”Ÿæˆ
        if w_pred_dir.exists():
            print(f"\n  ğŸ“Š Processing W_pred results...")
            for prob_dir in sorted(w_pred_dir.iterdir()):
                if prob_dir.is_dir() and prob_dir.name.startswith('prob_'):
                    print(f"    Processing: {prob_dir.name}")
                    output_dir = f'visualization_results/{output_base_name}/W_pred'
                    visualize_w_pred(str(prob_dir), output_dir, None)
        
        if w_pred_loss_w_dir.exists():
            print(f"\n  ğŸ“Š Processing W_pred_loss_W results...")
            for prob_dir in sorted(w_pred_loss_w_dir.iterdir()):
                if prob_dir.is_dir() and prob_dir.name.startswith('prob_'):
                    print(f"    Processing: {prob_dir.name}")
                    output_dir = f'visualization_results/{output_base_name}/W_pred_loss_W'
                    visualize_w_pred(str(prob_dir), output_dir, None)
    
    # å¯¹æ¯” Y é¢„æµ‹å™¨ vs W é¢„æµ‹å™¨ï¼ˆä¸¤ä¸ªç‰ˆæœ¬ï¼‰
    y_pred_dir = exp_dir / 'Y_pred'
    w_pred_dir = exp_dir / 'W_pred'
    w_pred_loss_w_dir = exp_dir / 'W_pred_loss_W'
    
    if y_pred_dir.exists() and (w_pred_dir.exists() or w_pred_loss_w_dir.exists()):
        print("\n  ğŸ“Š Comparing Y-Predictor vs W-Predictors...")
        for prob_dir_name in sorted([d.name for d in y_pred_dir.iterdir() if d.is_dir() and d.name.startswith('prob_')]):
            y_dir = y_pred_dir / prob_dir_name
            w_dir = w_pred_dir / prob_dir_name if w_pred_dir.exists() else None
            w_loss_w_dir = w_pred_loss_w_dir / prob_dir_name if w_pred_loss_w_dir.exists() else None
            
            if y_dir.exists() and (w_dir is not None or w_loss_w_dir is not None):
                print(f"    Comparing: {prob_dir_name}")
                output_dir = f'visualization_results/{output_base_name}/Comparison'
                compare_y_vs_w_predictor(
                    str(y_dir), 
                    str(w_dir) if w_dir and w_dir.exists() else None,
                    str(w_loss_w_dir) if w_loss_w_dir and w_loss_w_dir.exists() else None,
                    output_dir
                )


def find_experiment_dirs(base_dir, current_path=None, max_depth=10):
    """é€’å½’æŸ¥æ‰¾æ‰€æœ‰åŒ…å« Y_pred/W_pred/W_pred_loss_W çš„ç›®å½•
    
    Args:
        base_dir: åŸºç¡€ç›®å½•ï¼ˆPathå¯¹è±¡ï¼‰
        current_path: å½“å‰æ‰«æè·¯å¾„ï¼ˆPathå¯¹è±¡ï¼‰ï¼Œç”¨äºé€’å½’
        max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼Œé˜²æ­¢æ— é™é€’å½’
    
    Returns:
        list: [(exp_dir, output_name), ...] å…ƒç»„åˆ—è¡¨
    """
    if current_path is None:
        current_path = base_dir
    
    if max_depth <= 0:
        return []
    
    exp_dirs = []
    
    # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦åŒ…å« Y_pred/W_pred/W_pred_loss_W
    has_predictors = any((current_path / pred_type).exists() 
                        for pred_type in ['Y_pred', 'W_pred', 'W_pred_loss_W'])
    
    if has_predictors:
        # æ‰¾åˆ°å®éªŒç›®å½•ï¼Œç”Ÿæˆè¾“å‡ºåç§°
        try:
            rel_path = current_path.relative_to(base_dir)
            # å°†è·¯å¾„è½¬æ¢ä¸ºè¾“å‡ºåç§°ï¼šç”¨ _ æ›¿æ¢ /
            output_name = str(rel_path).replace('/', '_')
            exp_dirs.append((current_path, output_name))
        except ValueError:
            # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç›®å½•å
            output_name = current_path.name
            exp_dirs.append((current_path, output_name))
    else:
        # ç»§ç»­é€’å½’æ‰«æå­ç›®å½•
        try:
            for subdir in sorted(current_path.iterdir()):
                if not subdir.is_dir():
                    continue
                
                # è·³è¿‡æŸäº›ä¸éœ€è¦æ‰«æçš„ç›®å½•ï¼ˆå¯é€‰ï¼‰
                if subdir.name in ['.git', '__pycache__', 'ckpt']:
                    continue
                
                # é€’å½’æŸ¥æ‰¾
                exp_dirs.extend(find_experiment_dirs(base_dir, subdir, max_depth - 1))
        except (PermissionError, OSError):
            # å¿½ç•¥æ— æ³•è®¿é—®çš„ç›®å½•
            pass
    
    return exp_dirs


def main():
    """ä¸»å‡½æ•°ï¼šé€’å½’æ‰«ææ‰€æœ‰æµ‹è¯•ç»“æœå¹¶ç”Ÿæˆå¯è§†åŒ–
    
    å®Œå…¨è‡ªåŠ¨æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ç›®å½•ç»“æ„ï¼Œä¸é™åˆ¶ï¼š
    - ç›®å½•åå‰ç¼€
    - åµŒå¥—å±‚çº§
    - ç›®å½•ç»“æ„
    - è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šï¼‰
    
    æ”¯æŒçš„ä»»æ„ç›®å½•ç»“æ„ç¤ºä¾‹ï¼š
    - {input_dir}/{exp_name}/Y_pred/prob_*/
    - {input_dir}/LEN_VARIANCE/num_*/Y_pred/prob_*/
    - {input_dir}/NOISE/noise_std_*/Y_pred/prob_*/
    - {input_dir}/mc/xdim_*/Y_pred/prob_*/
    - {input_dir}/ä»»æ„/åµŒå¥—/å±‚çº§/Y_pred/prob_*/
    """
    parser = argparse.ArgumentParser(
        description='å¯è§†åŒ–æµ‹è¯•ç»“æœï¼Œé€’å½’æ‰«ææŒ‡å®šç›®å½•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python visualize.py                              # æ‰«æé»˜è®¤çš„ test_results/ ç›®å½•
  python visualize.py --input_dir test_results     # æ‰«æ test_results/ ç›®å½•
  python visualize.py --input_dir /path/to/results  # æ‰«æä»»æ„æŒ‡å®šç›®å½•
        """
    )
    parser.add_argument(
        '--input_dir',
        type=str,
        default='test_results',
        help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: test_resultsï¼‰'
    )
    
    args = parser.parse_args()
    base_dir = Path(args.input_dir)
    
    if not base_dir.exists():
        print(f"Error: ç›®å½•ä¸å­˜åœ¨: {base_dir}")
        print(f"è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ä½¿ç”¨ --input_dir æŒ‡å®šå…¶ä»–ç›®å½•")
        sys.exit(1)
    
    if not base_dir.is_dir():
        print(f"Error: {base_dir} ä¸æ˜¯ä¸€ä¸ªç›®å½•")
        sys.exit(1)
    
    print("="*70)
    print("Starting visualization for all test results...")
    print(f"Recursively scanning directory: {base_dir}")
    print("="*70)
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰åŒ…å«é¢„æµ‹å™¨ç›®å½•çš„å®éªŒç›®å½•
    exp_dirs = find_experiment_dirs(base_dir)
    
    if not exp_dirs:
        print("Warning: æœªæ‰¾åˆ°åŒ…å« Y_pred/W_pred/W_pred_loss_W çš„å®éªŒç›®å½•")
        print("æœŸæœ›çš„ç›®å½•ç»“æ„:")
        print(f"  {base_dir}/.../Y_pred/prob_*/")
        print(f"  {base_dir}/.../W_pred/prob_*/")
        print(f"  {base_dir}/.../W_pred_loss_W/prob_*/")
        return
    
    print(f"\næ‰¾åˆ° {len(exp_dirs)} ä¸ªå®éªŒç›®å½•éœ€è¦å¤„ç†:")
    for exp_dir, output_name in exp_dirs:
        print(f"  - {exp_dir} -> {output_name}")
    print()
    
    # å¤„ç†æ‰€æœ‰æ‰¾åˆ°çš„å®éªŒç›®å½•
    for exp_dir, output_name in exp_dirs:
        process_experiment_dir(exp_dir, output_name, base_dir)
    
    print("\n" + "="*70)
    print("âœ… Visualization complete!")
    print("="*70)
    print("Results saved in:")
    print("  - visualization_results/{exp_name}/Y_pred/")
    print("  - visualization_results/{exp_name}/W_pred/")
    print("  - visualization_results/{exp_name}/W_pred_loss_W/")
    print("  - visualization_results/{exp_name}/Comparison/")
    print("")
    print(f"Note: ç›®å½•åç§°è‡ªåŠ¨ä» {base_dir} çš„ç›®å½•ç»“æ„ç”Ÿæˆ")
    print("="*70)


if __name__ == '__main__':
    main()

